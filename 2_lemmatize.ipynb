{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9be7ba8d-401d-4019-9ece-ff66c47072cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import spacy.cli\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from joblib import Parallel, delayed\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd1d919e-20d9-4a40-814d-bdf61372b65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pickle to dataframe\n",
    "with open('speeches.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a37c70e0-c2aa-4450-bd92-29b4d5adcb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy.prefer_gpu()\n",
    "nlp = spacy.load('en_core_web_sm')#, disable=[\"parser\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffda00e-781e-419e-a546-c360881d960b",
   "metadata": {},
   "source": [
    "# Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4424ce6f-cbed-4638-91ef-12c35ac650e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# common procedural word indicating MP standing up requesting to speak\n",
    "nlp.Defaults.stop_words.add(\"rose\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a007970-7727-4770-870f-07759403cc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(doc, stop_words=nlp.Defaults.stop_words):\n",
    "    '''Takes a spacy doc and lemmatizes each of the tokens\n",
    "    \n",
    "    Takes alphanumeric tokens whose lowercase form does not appear in stop_words\n",
    "    and returns their lowercase lemmatized form\n",
    "    '''\n",
    "    lemmas = [token.lemma_.lower() for token in doc if token.is_alpha and token.text.lower() not in stop_words]\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd46683f-4931-4f8f-898c-3d0dafa39c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunk(texts, batch_size=50):\n",
    "    '''returns list, each item of which is a list of lemmas'''\n",
    "    preproc_pipe = []\n",
    "    for doc in nlp.pipe(texts, batch_size=batch_size):\n",
    "        preproc_pipe.append(lemmatize(doc))\n",
    "    return preproc_pipe\n",
    "\n",
    "def chunker(iterable, chunksize):\n",
    "    '''Takes an iterable and returns a list of chunks of the iterable'''\n",
    "    return (iterable[pos: pos + chunksize] for pos in range(0, len(iterable), chunksize))\n",
    "\n",
    "def flatten(list_of_lists):\n",
    "    '''Flatten a list of lists to a list'''\n",
    "    return [item for sublist in list_of_lists for item in sublist]\n",
    "\n",
    "def process_parallel(texts, chunksize=100, n_jobs=-1):\n",
    "    executor = Parallel(n_jobs=n_jobs, backend='multiprocessing', prefer='processes')\n",
    "    do = delayed(process_chunk)\n",
    "    tasks = (do(chunk) for chunk in chunker(texts, chunksize=chunksize))\n",
    "    result = executor(tasks)\n",
    "    return flatten(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efa73ce6-7930-4026-af55-3ff070460693",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for training on GPU - no parallelization\n",
    "# df['lemmas'] = process_chunk(df.speech, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94dc8887-f25f-475b-ae5f-bd38aa39aa17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.1 s, sys: 6.18 s, total: 43.3 s\n",
      "Wall time: 18min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# for training on CPU - parallelization\n",
    "df['lemmas'] = process_parallel(df.speech, chunksize=100, n_jobs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a2dadb5-52bd-43c7-878b-9004e9bc2ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "609719"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_len = len(df)\n",
    "raw_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "033741d7-46f9-44f7-ab3a-199c11c805a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.lemmas.apply(len) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "692f9796-0500-44bd-8eb8-c84d162d1e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11487\n",
      "0.019\n"
     ]
    }
   ],
   "source": [
    "print(raw_len - len(df))\n",
    "print(np.around((raw_len - len(df)) / raw_len, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153c604d-56e5-4b0c-be31-aa14a0fba3be",
   "metadata": {},
   "source": [
    "1.9% of contributions have no lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a174365-f75a-4115-88f3-a5eb657a5d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('speeches-lemmatized.pkl', 'wb') as f:\n",
    "    pickle.dump(df, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
